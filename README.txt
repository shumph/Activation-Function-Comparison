This project originates from my submission to the kaggle Digit recognizer contest back in 2020, which I came across from a youtube video of someone attempting to complete this challenge using only numpy, and I thought I'd try it for 
myself! Which was actually to a great success (at least relatively) my code was ~5% more accurate than the code the youtuber had created. In my tinkering I found myself curious to how the activation function effects the accuracy of
the digit recognizer, so I created this project to compare three common activation functions: hyperbolic tangent, rectified linear unit, and the sigmoid function. I used a very VERY ugly tkinter interface (visual stuff isn't my strong
suit) to illustrate the difference in accuracy over each iteration, and I used matplotlib to illustrate specific digits and each functuions respective guesses for the given digit. A little unsightly, but it was very fun to create.